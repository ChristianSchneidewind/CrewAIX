# Example .env for running CrewAiX with OpenAI (cloud)
# Copy it to `.env` locally and fill in your real API key:
# cp .env.example .env
# then edit .env and replace PLACEHOLDERS

# --- OpenAI configuration ---
# Official OpenAI API endpoint
OPENAI_API_BASE=https://api.openai.com/v1

# Your OpenAI API key (do NOT commit the real key!)
OPENAI_API_KEY=sk-your-openai-key-here

# Recommended: small + reasonably priced model for this project
# You can change this to any OpenAI chat model you have access to.
OPENAI_MODEL_NAME=gpt-4.1-mini

# --- Content configuration ---
# Paths are relative to the project root
TWEETS_MD_PATH=content/tweets.md
TWEET_TYPES_MD_PATH=content/tweet_types.md

# Output directory for generated tweets
OUT_DIR=out

# Number of tweets per run
# Start small when testing new models / prompts
N_TWEETS=1

# How many recent tweets to consider for de-duplication
RECENT_TWEETS_MAX=5

# --- Generation behavior ---
# Sampling temperature: lower = more deterministic, higher = more creative
TEMPERATURE=0.7

# Enable verbose logging from CrewAI agent (True/False)
VERBOSE=false

# --- LiteLLM noise reduction (safe defaults) ---
LITELLM_LOG=ERROR
LITELLM_DISABLE_TELEMETRY=true
LITELLM_SUPPRESS_DEBUG_INFO=true
LITELLM_LOCAL_MODEL_COST_MAP=true
LITELLM_LOGGING=False

LITELLM_ENABLE_PROXY=false
LITELLM_USE_PROXY=false
